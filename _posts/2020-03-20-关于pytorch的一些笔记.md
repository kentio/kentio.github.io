---
layout: post
title: 关于pytorch的一些笔记
subtitle: 
date: 2020-03-20
author: kevin
header-img: img/green-bg.jpg
catalog: true
tags:
    - deep learning
    - python
    - pytorch
---



## preface

深度学习框架学起来还是 pytorch 更舒服，简洁易懂，个人觉得比 tensorflow 学起来更轻松，并且目前学术界大多用的也都是 pytorch 来复现代码，所以这篇博客就记录一下我学习的过程中的笔记。



## torch.unsqueeze



`torch.unsqueeze(tensor, dim=x)` 用来给 tensor 升维，也就是加上一个维数为 1 的维度（dim 参数不能超过 tensor 的维度），例如

```python
import torch 
a = torch.rand((1, 2, 3))
a.size()
# torch.Size([1, 2, 3])
b = torch.unsqueeze(a, 2)
b.size()
# torch.Size([1, 2, 1, 3])
```

unsqueeze 这个函数还是挺常用的，例如在处理逻辑回归时输入的点为一维的数据，我们就要用 unsqueeze 来升维使其变成二维的数据。同理，`torch.squeeze(tensor, dim=x)`  就是用来降维的，如果不指定 dim 参数的话就默认将所有维数为 1 的维度都删除

```python
import torch 
a = torch.rand((1, 1, 2, 3))
a.size()
# torch.Size([1, 1, 2, 3])
b = torch.squeeze(a)
b.size()
# torch.Size([2, 3])
```

如果指定了 dim 参数的话，则将该 dim 上进行维度删除，如果该 dim 的维数不为 1 的话则 tensor 不变，为 1 的话则将该 dim 删除

```python
import torch 
a = torch.rand((1, 1, 2, 3))
a.size()
# torch.Size([1, 1, 2, 3])
b = torch.squeeze(a, 2)
b.size()
# torch.Size([1, 1, 2, 3])
c = torch.squeeze(a, 1)
c.size()
# torch.Size([1, 2, 3])
```



---

在XXXXXXXXXXXXXXXX



## visualization



在用 matplotlib 进行画图可视化时要用 `tensor.data.numpy()` 将 tensor 转化为 numpy 的 ndarray 数据，不能用代表 Variable 的 tensor 来画图



---

用了 GPU 训练的数据不能用 matplotlib 进行可视化，要用 `data.cpu()` 将其转到 CPU 上



---

在 jupyter notebook 上用 OpenCV 的 `cv2.imshow()` 会使进程崩溃，可以用 matplotlib 来代替

```python
import cv2
import matplotlib.pyplot as plt
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.show()
```

因为 OpenCV 储存的图像是 BGR 格式的，而 matplotlib 是 RGB 格式，所以要转换一下颜色空间再显示，否则颜色会有些奇怪





## GPU



将网络或数据从 CPU 转到 GPU 上可以用 `data.cuda()` 或者 `data.to('cuda')`，不过一般都用后面这种形式，因为会在前面加一行代码

```python
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
data.to(device)
```

这样就能使得没有 GPU 的情况下也需要改代码就能够跑模型了



---

网络结构较小的时候，CPU 和 GPU 之间进行数据传输耗时更高，这时用 CPU 更快，当网络庞大的时候，用 GPU 可以明显感觉到提速。我自己试了一个简单的回归网络，跑 200 个 epoch 在 CPU 上 2.5s ，GPU 要 6.6s



## train





## test

