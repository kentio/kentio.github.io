---
layout: post
title: 目标检测任务中的一些评估准则
subtitle: 
date: 2020-03-29
author: kevin
header-img: img/green-bg.jpg
catalog: true
tags:
    - object detection
    - deep learning
---



## preface



本篇文章介绍一下目标检测中常用的一些评估准则，大家跑 yolo 的时候可能看着一堆输出不知道啥意思，希望这篇文章能够解决大家的疑惑，主要是翻译 GitHub 上的一个 repo，原文是英文写的，链接[在这里](https://github.com/rafaelpadilla/Object-Detection-Metrics)，写的挺不错，就翻译过来给英文不好的同学看看，另外还加了几个项目中没有提到的准则



## 不同的竞赛有不同的指标



* [PASCAL VOC Challenge](http://host.robots.ox.ac.uk/pascal/VOC/) 提供了 Matlab 脚本，以便评估检测到的目标的质量， 竞赛的参与者可以在提交结果之前使用提供的 Matlab 脚本来测量其检测的准确性。 当前 PASCAL VOC 目标检测挑战所使用的度量标准是 `Precision x Recall` 曲线和 `Average Precision` 也就是 PR 曲线和平均精确度
* [COCO Detection Challenge](https://competitions.codalab.org/competitions/5181) 使用不同的指标来评估不同算法的目标检测的准确性。[点击此处](http://cocodataset.org/#detection-eval)可以找到说明 12 种度量标准的文档，这些度量标准用于表征 COCO 上目标检测器的性能。 该竞赛提供了 Python 和 Matlab 代码，因此用户可以在提交结果之前验证分数并且还需要将结果转换为比赛所需的格式。
* [Google Open Images Dataset V4 Competition](https://storage.googleapis.com/openimages/web/challenge.html) 使用 500 个类的平均平均精度 (mAP) 来评估对象检测任务。
* [ImageNet Object Localization Challenge](https://www.kaggle.com/c/imagenet-object-detection-challenge) 定义了每个图像的 error，其中考虑了类别以及真实标签与 Bounding Box 之间的 IOU， 总误差计算方法为所有测试数据集中最小误差的平均值（俺也没理解清楚这这句话到底啥意思==）



## 重要的概念



### Intersection Over Union (IOU)



这个好理解，做目标检测的时候，我们会提前标注数据，用一个 Box 将目标框起来，训练的时候也会生成 Bounding Box，检测定位得准不准就看生成的 BBox 和标注的 Box（也叫 ground truth）的重叠区域。IOU 就是二者的重叠区域面积与二者并集面积之比，越接近1 说明定位效果越好

![IOU](https://i.loli.net/2020/03/30/GcC56EULfqD2Kus.png)



### TP，FP，FN，TN



这四个是评估准则的一些基本概念:

- **True Positive (TP)**: 一次正确的检测. Detection with IOU ≥ *threshold*

- **False Positive (FP)**: 一次错误的检测. Detection with IOU < *threshold*

- **False Negative (FN)**: 一个目标没有被检测出来

- **True Negative (TN)**: 这个指标一般不会去用，它相当于 BBox 框在没有目标的地方

  

  *threshold*: 阈值，取决于具体准则，一般是 0.5，也有 0.75，0.95



前面三个都是在拥有 GroundTruth 下的三种情况，TN 是检测在了一个没有 GroundTruth 的地方



### Precision精确度



精确度是模型仅识别相关对象的能力，它是所有有效检测中正确检测的百分比



![precision](https://i.loli.net/2020/03/31/nuIrCfTZQzPcoX2.gif)

### Recall召回率



召回率是模型找到所有 GroundTruth Bbox 的能力，它是在所有相关的 GroundTruth Bbox 中检测到 TF 的百分比，并由下式给出



![recall](https://i.loli.net/2020/03/31/p6GxAyV9o7jIKgw.gif)



## 一些评估方法



### Precision x Recall curve - PR曲线





### Average Precision - AP平均精度



