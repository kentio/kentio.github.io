---
layout: post
title: CV深度学习面试问题记录
subtitle: 
date: 2020-06-30
author: kevin
header-img: img/green-bg.jpg
catalog: true
tags:
    - deep learning
    - job
---



## preface



这是在牛客网上根据大家的面经收集过来的题目，并以自己的理解来作出回答，也查阅了很多博客和资料。水平有限，不一定是正确的，欢迎指正，铁子们要找工作的时候可以看看



## 图像细粒度分类是什么



不同于普通的分类任务，图像细粒度分类是指的对同一个大类别进行更加细致的分类，例如哈士奇与柯基。



## RPN是怎么做的



## 过拟合欠拟合是啥，怎么解决？



### 过拟合



过拟合是指训练误差和测试误差之间的差距太大。模型在训练集上表现很好，但在测试集上却表现很差，也就是泛化能力差。引起的原因有 ①训练数据集样本单一，样本不足 ②训练数据中噪声干扰过大 ③模型过于复杂。



防止过拟合的几种方法：

1. 增加更多的训练集或者数据增强(根本上解决问题)
2. 采用更简单点的模型(奥卡姆剃刀准则，简单的就是正确的)
3. 正则化(L1，L2，Dropout)
4. 可以减少不必要的特征或使用较少的特征组合



### 欠拟合



欠拟合是指模型不能在训练集上获得足够低的误差。换句换说，就是模型复杂度低，模型在训练集上就表现很差，没法学习到数据背后的规律。



欠拟合基本上都会发生在训练刚开始的时候，经过不断训练之后欠拟合应该不怎么考虑了。欠拟合可以通过使用非线性模型来改善，也就是使用一个更强的模型，并且可以增加训练特征



## ResNet为啥能够解决梯度消失？怎么做的，能推导吗？



## 深度学习里面PCA的作用



PCA 用于降低维度，消除数据的冗余，减少一些不必要的特征。常用步骤如下（设有 m 条 n 维数据）：

1. 将原始数据按照列组成 m 行 n 列矩阵 X
2. 将 X 的每一列(代表一个属性字段)进行零均值化(去中心化)减去这一列的均值得到特征中心化后的矩阵 $B = X_i - \mu_i$
3. 求出协方差矩阵 $C = (X_i - \mu_i)*(X_i - \mu_i)^T$
4. 求出矩阵 C 的特征值($det|A-\lambda I|=0$)和特征向量，按照特征值的大小将对应的特征向量从左往右排列，取前 k 个最大的特征值对应的特征向量组成矩阵 P
5. Y = PX 即为降维到 k 维后的数据，即从 n 维降到了 k 维，保留了原本的大部分信息



> reference:
>
> 王兴政老师的PPT
>
> https://blog.csdn.net/Virtual_Func/article/details/51273985



## YOLOv3的框是怎么聚出来的？



YOLOv3 的框是作者通过对自己的训练集的 bbox 聚类聚出来的，本质上就是一个 kmeans 算法，原理如下：

1. 随机选取 k 个类别的中心点，代表各个聚类
2. 计算所有样本到这几个中心点的距离，将每个样本归为距离最小的类别
3. 更新每个类别的中心点(计算均值)
4. 重新进行步骤 2 ，直到类的中心点不再改变

![kmeans.png](https://i.loli.net/2020/07/01/dBGSP9543eQJTka.png)



YOLOv3 的 kmeans 想法不能直接用 w 和 h 来作为聚类计算距离的标准，因为 bbox 有大有小，不应该让 bbox 的尺寸影响聚类结果，因此，YOLOv3 的聚类使用了 IOU 思想来作为距离的度量
$$
d(bbox, centroid) = 1 - IOU(bbox, centroid)
$$
也就是说 IOU 越大的话，表示 bbox 和 box_cluster 就越类似，于是将 bbox 划归为 box_cluster



在 AlexeyAB 大佬改进的 darknet 中实现了这个过程，具体就是加载所有训练集中的 bbox 的 w 和 h，随机选择 k 个作为 centroids，然后用所有样本去和这 k 个 centroids 做 IOU 得出距离，并将样本归为距离最小的 cluster，然后更新 centroids 重复上面的步骤，直到 centroids 不再更新



> reference:
>
> https://github.com/AlexeyAB/darknet/blob/master/scripts/gen_anchors.py
>
> https://www.cnblogs.com/sdu20112013/p/10937717.html



## YOLO和SSD的本质区别？



## R-CNN系列和SSD本质有啥不一样吗？



## SSD的致命缺点？如何改进



需要人工设置prior box的min_size，max_size和aspect_ratio值。网络中prior box的基础大小和形状不能直接通过学习获得，而是需要手工设置。而网络中每一层feature使用的prior box大小和形状恰好都不一样，导致调试过程非常依赖经验。
虽然采用了pyramdial feature hierarchy的思路，但是对小目标的recall依然一般，并没有达到碾压Faster RCNN的级别。作者认为，这是由于SSD使用conv4_3低级feature去检测小目标，而低级特征卷积层数少，存在特征提取不充分的问题。
————————————————
版权声明：本文为CSDN博主「一个新新的小白」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/qq_31511955/article/details/80597211



## 怎么解决梯度消失和梯度弥散



## YOLOv1到YOLOv3的发展历程以及解决的问题





## 常见的Loss，回归的，分类的，Focal Loss



### Focal Loss



>  reference: https://www.cnblogs.com/king-lps/p/9497836.html





## L1、L2范数是什么，区别呢？



范数是具有 “长度” 概念的函数。在向量空间内，为所有的向量的赋予非零的增长度或者大小。不同的范数，所求的向量的长度或者大小是不同的。举个例子，2 维空间中，向量 (3,4) 的长度是 5，那么 5 就是这个向量的一个范数的值，更确切的说，是欧式范数或者L2范数的值。



更一般的情况下，对于一个 p- 范数，如果 $x = [x_1, x_2, x_3, …, x_n]^T$， 那么向量 x 的 p- 范数就是
$$
\begin{equation}

||x||_p = (|x_1|^p+|x_2|^p+…+|x_n|^p)^{1/p}

\end{equation}
$$
那么 L1 范数就是 p 为 1 的时候，也就是向量内所有元素的绝对值之和：
$$
\begin{equation}

||x||_p = (|x_1|+|x_2|+…+|x_n|)

\end{equation}
$$
L2 范数就是向量内所有元素的平方相加然后再开方：
$$
\begin{equation}

||x||_p = (|x_1|^2+|x_2|^2+…+|x_n|^2)^{1/2}

\end{equation}
$$
特别的，L0 范数是指向量中非零元素的个数！



---

在深度学习中，常常会在最后的 loss 函数中加一个正则项，将模型的权重 W 作为参数传入范数中，为的就是最小化 loss，



> reference: 
>
> https://zhuanlan.zhihu.com/p/28023308
>
> https://wangjie-users.github.io/2018/11/28/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3L1%E3%80%81L2%E8%8C%83%E6%95%B0/



## pooling layer怎么反向传播



池化层没有可以训练的参数，因此在卷积神经网络的训练中，池化层只需要将误差传递到上一层，并不需要做梯度的计算。要追求一个原则，那就是梯度之和不变。



* average pooling

直接将梯度平均分到对应的多个像素中，可以保证梯度之和是不变的

![average](https://i.loli.net/2020/06/30/KocaU1zbxnXYsyJ.jpg)

* max pooling

max pooling要记录下最大值像素的index，然后在反向传播时将梯度传递给值最大的一个像素，其他像素不接受梯度，也就是为0

![max](https://i.loli.net/2020/06/30/CZnUSwEcFy84JVL.jpg)

> reference: https://blog.csdn.net/qq_21190081/article/details/72871704



## 手撸IOU计算公式



```python
def bb_intersection_over_union(boxA, boxB):
    boxA = [int(x) for x in boxA]
    boxB = [int(x) for x in boxB]

    xA = max(boxA[0], boxB[0])
    yA = max(boxA[1], boxB[1])
    xB = min(boxA[2], boxB[2])
    yB = min(boxA[3], boxB[3])

    interArea = max(0, xB - xA ) * max(0, yB - yA)

    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])
    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])
    
    iou = interArea / float(boxAArea + boxBArea - interArea)

    return iou
```

